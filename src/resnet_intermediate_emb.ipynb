{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d8366b",
   "metadata": {},
   "source": [
    "### Libraries and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "import shutil\n",
    "from transformers import AutoImageProcessor, ResNetModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[INFO] Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c04f3b",
   "metadata": {},
   "source": [
    "### Model initialization and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8705cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-50 model\n",
    "model_name = \"microsoft/resnet-50\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = ResNetModel.from_pretrained(model_name).to(device)\n",
    "print(\"\\n[INFO] ResNet model loaded.\\n\")\n",
    "\n",
    "\n",
    "# Paths\n",
    "images_folder = os.path.join(\"..\", \"..\", \"miniImageNet\", \"images\")  # Path to MiniImageNet images folder\n",
    "save_path = os.path.join(\"D:\", \"CV_Project\", \"resnet_emb_intermediate\")  # Path where to save the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c468b",
   "metadata": {},
   "source": [
    "### Extraction of Training and Validation images embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold intermediate outputs\n",
    "intermediate_outputs = {}\n",
    "\n",
    "# Function to create a hook\n",
    "def get_hook(idx):\n",
    "    # Hook function to capture the output of each stage\n",
    "    def hook(module, input, output):\n",
    "        intermediate_outputs[f\"stage_{idx}\"] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks to each stage of the ResNet model\n",
    "for idx, stage in enumerate(model.encoder.stages):\n",
    "    stage.register_forward_hook(get_hook(idx))\n",
    "\n",
    "\n",
    "# Extract image names from CSV files (train and validation)\n",
    "csv1 = os.path.join(\"..\", \"..\", \"miniImageNet\", \"train_stratified.csv\")\n",
    "csv2 = os.path.join(\"..\", \"..\", \"miniImageNet\", \"validation_stratified.csv\")\n",
    "df = pd.concat([pd.read_csv(csv1), pd.read_csv(csv2)], ignore_index=True)\n",
    "image_names = df['filename'].tolist()\n",
    "\n",
    "\n",
    "# Loop through images and extract embeddings\n",
    "for file_name in tqdm(image_names, desc=\"Processing images\"):\n",
    "    # extract and preprocess image\n",
    "    image_path = os.path.join(images_folder, file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    W, H = image.size\n",
    "    scale = 384 / min(W, H)\n",
    "    new_W = int(W * scale)\n",
    "    new_H = int(H * scale)\n",
    "    image = image.resize((new_W, new_H), resample=Image.BICUBIC)\n",
    "    W, H = image.size\n",
    "    crop_size = min(W, H)\n",
    "    left = (W - crop_size) // 2\n",
    "    top = (H - crop_size) // 2\n",
    "    image = image.crop((left, top, left + crop_size, top + crop_size))\n",
    "\n",
    "\n",
    "    # Prepare inputs\n",
    "    inputs = processor(image, return_tensors=\"pt\", do_resize=False, do_center_crop=False).to(device)\n",
    "\n",
    "    # Clear previous intermediate outputs\n",
    "    intermediate_outputs.clear()\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Convert tensors to CPU and float16\n",
    "    embeddings_dict = {name: tensor.cpu().to(torch.float16) for name, tensor in intermediate_outputs.items()}\n",
    "\n",
    "    # Save embeddings using a temporary file for atomicity\n",
    "    filename = os.path.join(save_path, file_name.split(\".\")[0] + \".pt\")\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "        torch.save(embeddings_dict, tmp.name)\n",
    "        tmp.flush()\n",
    "        os.fsync(tmp.fileno())\n",
    "    shutil.move(tmp.name, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
