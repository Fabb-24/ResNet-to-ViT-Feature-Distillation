{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c92014",
   "metadata": {},
   "source": [
    "### Libraries and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c9cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from transformers import ResNetModel\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2dbb5",
   "metadata": {},
   "source": [
    "## 1. Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a79f20",
   "metadata": {},
   "source": [
    "### Adaptive Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663f2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStageAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    Modello che riceve embedding di 4 stage di ResNet e li converte in embedding per Qwen.\n",
    "    \"\"\"\n",
    "    def __init__(self, stage_channels=[256, 512, 1024, 2048], out_dim=2048, hidden_multiplier=2):\n",
    "        super().__init__()\n",
    "        self.projections = nn.ModuleList([\n",
    "            nn.Conv2d(c, out_dim, kernel_size=1) for c in stage_channels\n",
    "        ])\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Conv2d(out_dim * len(stage_channels), out_dim * hidden_multiplier, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_dim * hidden_multiplier, out_dim, kernel_size=1)\n",
    "        )\n",
    "        # Definiamo il layer di Layer Normalization.\n",
    "        self.final_norm = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, stage0, stage1, stage2, stage3, target_seq_len=196):\n",
    "        B, _, Ht, Wt = stage3.shape\n",
    "        proj_feats = []\n",
    "        for feat, proj in zip([stage0, stage1, stage2, stage3], self.projections):\n",
    "            x = proj(feat)\n",
    "            x = F.interpolate(x, size=(Ht, Wt), mode='bilinear', align_corners=False)\n",
    "            proj_feats.append(x)\n",
    "\n",
    "        fused = torch.cat(proj_feats, dim=1)  # (B, out_dim*4, Ht, Wt)\n",
    "        fused = self.fusion(fused)           # (B, out_dim, Ht, Wt)\n",
    "        seq = fused.flatten(2)               # (B, out_dim, Ht*Wt)\n",
    "        seq = F.interpolate(seq, size=target_seq_len, mode='linear', align_corners=False)\n",
    "        seq = seq.permute(0, 2, 1)           # (B, L, C)\n",
    "        \n",
    "        # Applichiamo la normalizzazione come ultimo passo.\n",
    "        seq = self.final_norm(seq)\n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5ae00",
   "metadata": {},
   "source": [
    "### Composite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d224c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNetModel.from_pretrained(\"microsoft/resnet-50\")\n",
    "        self.adapter = MultiStageAdapter()\n",
    "\n",
    "    def forward(self, pixel_values, target_seq_len=196):\n",
    "        intermediate_outputs = {}\n",
    "\n",
    "        def get_hook(idx):\n",
    "            def hook(module, input, output):\n",
    "                intermediate_outputs[f\"stage_{idx}\"] = output\n",
    "            return hook\n",
    "\n",
    "        hooks = []\n",
    "        for idx, stage in enumerate(self.resnet.encoder.stages):\n",
    "            hooks.append(stage.register_forward_hook(get_hook(idx)))\n",
    "\n",
    "        intermediate_outputs.clear()\n",
    "        _ = self.resnet(pixel_values)  # forward pass\n",
    "\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        stage0, stage1, stage2, stage3 = (\n",
    "            intermediate_outputs[\"stage_0\"],\n",
    "            intermediate_outputs[\"stage_1\"],\n",
    "            intermediate_outputs[\"stage_2\"],\n",
    "            intermediate_outputs[\"stage_3\"],\n",
    "        )\n",
    "\n",
    "        projected = self.adapter(stage0, stage1, stage2, stage3, target_seq_len)\n",
    "        return projected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b234a1c",
   "metadata": {},
   "source": [
    "## 2. Dataset and Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d10ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageQwenDataset(Dataset):\n",
    "    def __init__(self, image_folder, qwen_folder, valid_image_names, image_size=384):\n",
    "        self.image_folder = image_folder\n",
    "        self.qwen_folder = qwen_folder\n",
    "        self.image_files = sorted([f for f in os.listdir(image_folder) if f in valid_image_names])\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        qwen_path = os.path.join(self.qwen_folder, os.path.splitext(img_name)[0] + \".pt\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        W, H = image.size\n",
    "        scale = self.image_size / min(W, H)\n",
    "        new_W = int(W * scale)\n",
    "        new_H = int(H * scale)\n",
    "        image = image.resize((new_W, new_H), resample=Image.BICUBIC)\n",
    "        W, H = image.size\n",
    "        crop_size = min(W, H)\n",
    "        left = (W - crop_size) // 2\n",
    "        top = (H - crop_size) // 2\n",
    "        image = image.crop((left, top, left + crop_size, top + crop_size))\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        image = transform(image)\n",
    "\n",
    "        qwen_embedding = torch.load(qwen_path)  # [L, D]\n",
    "\n",
    "        if torch.isnan(qwen_embedding).any() or torch.isinf(qwen_embedding).any():\n",
    "            #print(f\"Warning: Corrupted data in {qwen_path}\")\n",
    "            return None\n",
    "        # check if the image tensor has NaN or Inf values\n",
    "        if torch.isnan(image).any() or torch.isinf(image).any():\n",
    "            #print(f\"Warning: Corrupted image in {img_path}\")\n",
    "            return None\n",
    "\n",
    "        return image, qwen_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88d6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Filtra i campioni None\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "\n",
    "    images, qwen_list = zip(*batch)\n",
    "    images_batch = torch.stack(images)\n",
    "    qwen_batch = torch.stack(qwen_list)\n",
    "    return images_batch, qwen_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfd9fe",
   "metadata": {},
   "source": [
    "## 3. Saving and Plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa9adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_plots(train_losses_history, val_losses_history, epoch, checkpoint_dir):\n",
    "    \"\"\"\n",
    "    Function that saves training and validation loss plots for each epoch.\n",
    "\n",
    "    Args:\n",
    "        train_losses_history: List of training losses for each epoch.\n",
    "        val_losses_history: List of validation losses for each epoch.\n",
    "        epoch: Current epoch number (for naming the plot).\n",
    "        checkpoint_dir: Directory where the plot will be saved.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses_history, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses_history, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Zoomed-in plot for the last 10 epochs (if available)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    start_idx = max(0, len(train_losses_history) - 10)\n",
    "    epochs_range = range(start_idx, len(train_losses_history))\n",
    "    if len(epochs_range) > 1:\n",
    "        plt.plot(epochs_range, train_losses_history[start_idx:], label='Training Loss', color='blue')\n",
    "        plt.plot(epochs_range, val_losses_history[start_idx:], label='Validation Loss', color='red')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Last 10 Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(checkpoint_dir, f'training_progress_epoch_{epoch+1}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9bf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, epoch, train_loss, val_loss, checkpoint_dir, is_best=False, keep_last_n=3):\n",
    "    \"\"\"\n",
    "    Function that saves a checkpoint of the model handling the best N models.\n",
    "\n",
    "    Args:\n",
    "        model: The model to save.\n",
    "        optimizer: The optimizer state to save.\n",
    "        scheduler: The scheduler state to save.\n",
    "        epoch: Current epoch number.\n",
    "        train_loss: Training loss for the current epoch.\n",
    "        val_loss: Validation loss for the current epoch.\n",
    "        checkpoint_dir: Directory where the checkpoint will be saved.\n",
    "        is_best: Boolean indicating if this is the best model so far.\n",
    "        keep_last_n: Number of best models to keep.\n",
    "\n",
    "    Returns:\n",
    "        str: Filename of the saved checkpoint if it is the best model, otherwise None.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "    }\n",
    "    \n",
    "    # Save the last checkpoint\n",
    "    torch.save(checkpoint, os.path.join(checkpoint_dir, 'last_checkpoint.pth'))\n",
    "    \n",
    "    if is_best:\n",
    "        # Handle the best N models\n",
    "        best_models_info_path = os.path.join(checkpoint_dir, 'best_models_info.json')\n",
    "        \n",
    "        # Load existing best models info if it exists\n",
    "        if os.path.exists(best_models_info_path):\n",
    "            with open(best_models_info_path, 'r') as f:\n",
    "                best_models = json.load(f)\n",
    "        else:\n",
    "            best_models = []\n",
    "        \n",
    "        # Add the new model info\n",
    "        new_model_info = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'filename': f'best_model_epoch_{epoch+1}_loss_{val_loss:.4f}.pth'\n",
    "        }\n",
    "        best_models.append(new_model_info)\n",
    "        \n",
    "        # Order by validation loss and keep only the best N\n",
    "        best_models.sort(key=lambda x: x['val_loss'])\n",
    "        \n",
    "        # Remove worst model files if necessary\n",
    "        if len(best_models) > keep_last_n:\n",
    "            models_to_remove = best_models[keep_last_n:]\n",
    "            for model_info in models_to_remove:\n",
    "                old_file_path = os.path.join(checkpoint_dir, model_info['filename'])\n",
    "                if os.path.exists(old_file_path):\n",
    "                    os.remove(old_file_path)\n",
    "            best_models = best_models[:keep_last_n]\n",
    "        \n",
    "        # Save the new checkpoint\n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, new_model_info['filename']))\n",
    "        \n",
    "        # Update the info file with the new best models\n",
    "        with open(best_models_info_path, 'w') as f:\n",
    "            json.dump(best_models, f, indent=2)\n",
    "        \n",
    "        print(f\"New best model saved: {new_model_info['filename']}\")\n",
    "        return new_model_info['filename']\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb25b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer=None, scheduler=None):\n",
    "    \"\"\"\n",
    "    Function that loads a checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file.\n",
    "        model: The model to load the state into.\n",
    "        optimizer: The optimizer to load the state into (optional).\n",
    "        scheduler: The scheduler to load the state into (optional).\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing the epoch number, training loss, and validation loss.\n",
    "    \"\"\"\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    # Set weights_only=False to allow loading of all necessary Python/NumPy objects.\n",
    "    # Use this only because you trust the source of your checkpoint file.\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    epoch = checkpoint['epoch']\n",
    "    # The .get() method is safer in case these keys don't exist\n",
    "    train_loss = checkpoint.get('train_loss', float('inf'))\n",
    "    val_loss = checkpoint.get('val_loss', float('inf'))\n",
    "    \n",
    "    print(f\"Checkpoint loaded: Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    return epoch, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea86db",
   "metadata": {},
   "source": [
    "## 4. Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e09937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Class for early stopping during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience=20, min_delta=1e-4, restore_best_weights=True):\n",
    "        \"\"\"\n",
    "        Early stopping to stop training when it no longer improves.\n",
    "\n",
    "        Args:\n",
    "            patience: Number of epochs to wait for improvement before stopping.\n",
    "            min_delta: Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            restore_best_weights: Whether to restore model weights from the epoch with the best validation loss.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Check if training should be stopped.\n",
    "\n",
    "        Args:\n",
    "            val_loss: Current validation loss.\n",
    "            model: The model whose weights may be restored if early stopping is triggered.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if training should be stopped, False otherwise.\n",
    "        \"\"\"\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            \n",
    "        return self.early_stop\n",
    "    \n",
    "    def restore_weights(self, model):\n",
    "        \"\"\"\n",
    "        Restore the weights of the model to the best weights found during training.\n",
    "        \"\"\"\n",
    "        if self.best_weights is not None:\n",
    "            best_weights_on_device = {k: v.to(model.state_dict()[k].device) \n",
    "                                    for k, v in self.best_weights.items()}\n",
    "            model.load_state_dict(best_weights_on_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11135d9b",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5992dd2",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c8b20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMAGES_FOLDER = os.path.join(\"..\", \"..\", \"CV_data\", \"miniImageNet\")\n",
    "QWEN_EMBEDDINGS_PATH = os.path.join(\"..\", \"..\", \"CV_data\", \"separated_embeddings\", \"qwen_384\")\n",
    "CSV_TRAIN = os.path.join(\"..\", \"assets\", \"train_images.csv\")\n",
    "\n",
    "# Image parameters\n",
    "IMAGE_SIZE = 384\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE_RESNET = 1e-3\n",
    "LEARNING_RATE_ADAPTER = 1e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "MAX_EPOCHS = 100     \n",
    "CHECKPOINT_DIR = os.path.join(\"..\", \"models\", \"composite_model_checkpoints\")\n",
    "RESUME_TRAINING = True\n",
    "KEEP_BEST_N = 3\n",
    "\n",
    "# Early stopping parameters\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "EARLY_STOPPING_MIN_DELTA = 1e-3\n",
    "\n",
    "# Create the checkpoint directory if it doesn't exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60fe4ca",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a0c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_csv = pd.read_csv(CSV_TRAIN)\n",
    "images_list = images_csv['filename'].tolist()\n",
    "\n",
    "dataset = ImageQwenDataset(IMAGES_FOLDER, QWEN_EMBEDDINGS_PATH, images_list, image_size=IMAGE_SIZE)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9108be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CompositeModel().to(device)\n",
    "\n",
    "for param in model.resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.adapter.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.resnet.parameters(), 'lr': LEARNING_RATE_RESNET},\n",
    "    {'params': model.adapter.parameters(), 'lr': LEARNING_RATE_ADAPTER}\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-5\n",
    ")\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "scaler = torch.amp.GradScaler(device)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=EARLY_STOPPING_PATIENCE, \n",
    "    min_delta=EARLY_STOPPING_MIN_DELTA, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Tracking variables\n",
    "best_val_loss = float('inf')\n",
    "start_epoch = 0\n",
    "train_losses_history = []\n",
    "val_losses_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca9e01",
   "metadata": {},
   "source": [
    "### Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd468f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting new training from scratch...\n"
     ]
    }
   ],
   "source": [
    "if RESUME_TRAINING:\n",
    "    last_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'last_checkpoint.pth')\n",
    "    if os.path.exists(last_checkpoint_path):\n",
    "        try:\n",
    "            start_epoch, last_train_loss, best_val_loss = load_checkpoint(\n",
    "                last_checkpoint_path, model, optimizer, scheduler\n",
    "            )\n",
    "            start_epoch += 1\n",
    "            \n",
    "            # Load history if available\n",
    "            history_path = os.path.join(CHECKPOINT_DIR, 'loss_history.json')\n",
    "            if os.path.exists(history_path):\n",
    "                with open(history_path, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                    train_losses_history = history.get('train_losses', [])\n",
    "                    val_losses_history = history.get('val_losses', [])\n",
    "            \n",
    "            # Update early stopping with previous history\n",
    "            if val_losses_history:\n",
    "                early_stopping.best_loss = min(val_losses_history)\n",
    "                best_epoch_idx = val_losses_history.index(early_stopping.best_loss)\n",
    "                early_stopping.counter = len(val_losses_history) - 1 - best_epoch_idx\n",
    "                print(f\"Early stopping restored: best_loss={early_stopping.best_loss:.4f}, counter={early_stopping.counter}\")\n",
    "\n",
    "            print(f\"Training resumed from epoch {start_epoch}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "            print(\"Start new training from scratch...\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting new training from scratch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8108620",
   "metadata": {},
   "source": [
    "### Epoch training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f5ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_training(model, train_dataloader, loss_function, optimizer, scaler):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_loop = tqdm(train_dataloader, desc=f\"Training\")\n",
    "    num_train_batches = 0\n",
    "    \n",
    "    for i, batch_data in enumerate(train_loop):\n",
    "        if batch_data[0] is None:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            imgs, qwen_embs = batch_data\n",
    "            imgs = imgs.to(device)\n",
    "            qwen_embs = qwen_embs.to(device)\n",
    "\n",
    "            num_train_batches += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device):\n",
    "                target_seq_len = qwen_embs.shape[1]\n",
    "                pred = model(imgs, target_seq_len=target_seq_len)\n",
    "                loss = loss_function(pred, qwen_embs)\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"\\n Loss non valida al batch {i}, saltato.\")\n",
    "                continue\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n Errore batch {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    mean_loss = np.mean(train_losses) if train_losses else float('inf')\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58b8d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_validation(model, val_dataloader, loss_function):\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_loop = tqdm(val_dataloader, desc=f\"Validation\")\n",
    "    num_val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch_data in enumerate(val_loop):\n",
    "            if batch_data[0] is None:\n",
    "                continue\n",
    "\n",
    "            imgs, qwen_embs = batch_data\n",
    "            imgs = imgs.to(device)\n",
    "            qwen_embs = qwen_embs.to(device)\n",
    "\n",
    "            num_val_batches += 1\n",
    "\n",
    "            with torch.amp.autocast(device):\n",
    "                pred = model(imgs, target_seq_len=qwen_embs.shape[1])\n",
    "                loss = loss_function(pred, qwen_embs)\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"Invalid loss at batch {num_val_batches}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    mean_loss = np.mean(val_losses) if val_losses else float('inf')\n",
    "\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47875a8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1060563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_evaluation(model, train_loss, val_loss, optimizer, scheduler, epoch, early_stopping):\n",
    "    \"\"\"\n",
    "    Function that evaluates the model at the end of each epoch, updates the learning rate,\n",
    "    checks for early stopping, and saves the model checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model: The model to evaluate.\n",
    "        train_loss: Training loss for the current epoch.\n",
    "        val_loss: Validation loss for the current epoch.\n",
    "        optimizer: Optimizer used for training.\n",
    "        scheduler: Learning rate scheduler.\n",
    "        epoch: Current epoch number.\n",
    "        early_stopping: EarlyStopping instance to check for stopping conditions.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if training should stop, False otherwise.\n",
    "        train_loss: Training loss for the current epoch.\n",
    "        val_loss: Validation loss for the current epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    train_losses_history.append(train_loss)\n",
    "    val_losses_history.append(val_loss)\n",
    "    \n",
    "    # Update scheduler\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Epoch results\n",
    "    print(f\"\\n EPOCH RESULTS {epoch + 1}:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"   Learning Rate: {new_lr:.2e}\")\n",
    "    if old_lr != new_lr:\n",
    "        print(f\" LR reduced: {old_lr:.2e} → {new_lr:.2e}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\n EARLY STOPPING ACTIVATED!\")\n",
    "        print(f\"   Epoch: {epoch + 1}\")\n",
    "        print(f\"   Best val_loss: {early_stopping.best_loss:.4f}\")\n",
    "        print(f\"   Epochs without improvement: {early_stopping.patience}\")\n",
    "        \n",
    "        if early_stopping.restore_best_weights:\n",
    "            early_stopping.restore_weights(model)\n",
    "            print(\" Restored weights of the best model\")\n",
    "                    \n",
    "        # Save the best model checkpoint\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, train_loss, \n",
    "                        early_stopping.best_loss, CHECKPOINT_DIR, is_best=True, keep_last_n=KEEP_BEST_N)\n",
    "        \n",
    "        completion_reason = \"early_stopping\"\n",
    "        training_completed = True\n",
    "        return True, train_loss, val_loss\n",
    "    \n",
    "    print(f\"Early stopping: {early_stopping.counter}/{early_stopping.patience}\")\n",
    "    return False, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e7585",
   "metadata": {},
   "source": [
    "### Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ec43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 1/100\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 672/5100 [04:36<29:51,  2.47it/s, loss=2.6175]"
     ]
    }
   ],
   "source": [
    "training_completed = False\n",
    "completion_reason = \"unknown\"\n",
    "\n",
    "try:\n",
    "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
    "        print(f\"\\n EPOCH {epoch + 1}/{MAX_EPOCHS}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Training\n",
    "        train_loss = epoch_training(model, train_loader, loss_function, optimizer, scaler)\n",
    "        if train_loss is None:\n",
    "            continue\n",
    "\n",
    "        # Validation\n",
    "        val_loss = epoch_validation(model, val_loader, loss_function)\n",
    "        if val_loss is None:\n",
    "            continue\n",
    "\n",
    "        # Evaluation\n",
    "        stopped, avg_train_loss, avg_val_loss = epoch_evaluation(model, train_loss, val_loss, optimizer, scheduler, epoch, early_stopping)\n",
    "        if stopped:\n",
    "            training_completed = True\n",
    "            completion_reason = \"early_stopping\"\n",
    "            break\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss, CHECKPOINT_DIR)\n",
    "        \n",
    "        # Save best model\n",
    "        is_best = avg_val_loss < best_val_loss\n",
    "        if is_best:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss, \n",
    "                CHECKPOINT_DIR, is_best=True, keep_last_n=KEEP_BEST_N\n",
    "            )\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        # Save plots every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            save_training_plots(train_losses_history, val_losses_history, epoch, CHECKPOINT_DIR)\n",
    "        \n",
    "        # Save loss history\n",
    "        history = {\n",
    "            'train_losses': train_losses_history,\n",
    "            'val_losses': val_losses_history\n",
    "        }\n",
    "        with open(os.path.join(CHECKPOINT_DIR, 'loss_history.json'), 'w') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "    \n",
    "\n",
    "    if not training_completed:\n",
    "        completion_reason = \"max_epochs_reached\"\n",
    "        training_completed = True\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nTraining manually interrupted at epoch {epoch + 1}\")\n",
    "    completion_reason = \"manual_interruption\"\n",
    "    training_completed = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during training: {e}\")\n",
    "    print(\"\\nStack trace:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"Saving current state...\")\n",
    "    save_checkpoint(model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss, CHECKPOINT_DIR)\n",
    "    completion_reason = \"error\"\n",
    "    training_completed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ce862",
   "metadata": {},
   "source": [
    "## 6. Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6180fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch = epoch + 1 if 'epoch' in locals() else start_epoch\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Effective epochs: {final_epoch}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "if completion_reason == \"early_stopping\":\n",
    "    print(f\"Stopped with early stopping after {early_stopping.patience} epochs without improvement\")\n",
    "elif completion_reason == \"max_epochs_reached\":\n",
    "    print(\"All scheduled epochs completed\")\n",
    "elif completion_reason == \"manual_interruption\":\n",
    "    print(\"Training manually interrupted\")\n",
    "elif completion_reason == \"error\":\n",
    "    print(\"Training stopped due to an error\")\n",
    "\n",
    "\n",
    "# Save final plots\n",
    "if train_losses_history:\n",
    "    save_training_plots(train_losses_history, val_losses_history, final_epoch-1, CHECKPOINT_DIR)\n",
    "\n",
    "# Best models info\n",
    "best_models_info_path = os.path.join(CHECKPOINT_DIR, 'best_models_info.json')\n",
    "if os.path.exists(best_models_info_path):\n",
    "    with open(best_models_info_path, 'r') as f:\n",
    "        best_models = json.load(f)\n",
    "    print(f\"\\n Best {len(best_models)} models saved:\")\n",
    "    for i, model_info in enumerate(best_models):\n",
    "        print(f\"   {i+1}. Epoch {model_info['epoch']+1}: {model_info['filename']}\")\n",
    "        print(f\"      Val Loss: {model_info['val_loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
