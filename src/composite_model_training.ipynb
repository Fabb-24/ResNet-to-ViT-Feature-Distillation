{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c92014",
   "metadata": {},
   "source": [
    "### Libraries and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "from models.MultiStage_FtResnet_V2 import CompositeModel\n",
    "from util import preprocess_image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b234a1c",
   "metadata": {},
   "source": [
    "## 1. Dataset and Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageQwenDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading images and their corresponding Qwen embeddings.\n",
    "    Assumes images are in image_folder and Qwen embeddings are in qwen_folder with the same base filename.\n",
    "    Only loads images whose filenames are in valid_image_names.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_folder, qwen_folder, valid_image_names, image_size=384):\n",
    "        \"\"\"\n",
    "        Constructor for the dataset.\n",
    "\n",
    "        Args:\n",
    "            image_folder (str): Path to the folder containing images.\n",
    "            qwen_folder (str): Path to the folder containing Qwen embeddings.\n",
    "            valid_image_names (list): List of valid image filenames to include.\n",
    "            image_size (int): Size to which images will be resized (image_size x image_size).\n",
    "        \"\"\"\n",
    "\n",
    "        self.image_folder = image_folder\n",
    "        self.qwen_folder = qwen_folder\n",
    "        self.image_files = sorted([f for f in os.listdir(image_folder) if f in valid_image_names])\n",
    "        self.image_size = image_size\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of samples.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.image_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the image and its corresponding Qwen embedding at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image_tensor, qwen_embedding) where image_tensor is a tensor of shape [3, image_size, image_size]\n",
    "        \"\"\"\n",
    "\n",
    "        # Paths to the image and Qwen embedding\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        qwen_path = os.path.join(self.qwen_folder, os.path.splitext(img_name)[0] + \".pt\")\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = preprocess_image(img_path, self.image_size)\n",
    "\n",
    "        # Transform the image to tensor\n",
    "        transform = transforms.Compose([transforms.ToTensor(),])\n",
    "        image = transform(image)\n",
    "\n",
    "        # Load the Qwen embedding\n",
    "        qwen_embedding = torch.load(qwen_path)\n",
    "\n",
    "        # check if the Qwen embedding tensor or the image tensor has NaN or Inf values\n",
    "        if torch.isnan(qwen_embedding).any() or torch.isinf(qwen_embedding).any():\n",
    "            #print(f\"Warning: Corrupted data in {qwen_path}\")\n",
    "            return None\n",
    "        if torch.isnan(image).any() or torch.isinf(image).any():\n",
    "            #print(f\"Warning: Corrupted image in {img_path}\")\n",
    "            return None\n",
    "\n",
    "        return image, qwen_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle None values in the batch.\n",
    "    Filters out None values and stacks the remaining tensors.\n",
    "\n",
    "    Args:\n",
    "        batch (list): List of samples, where each sample is a tuple (image_tensor, qwen_embedding) or None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (images_batch, qwen_batch) where images_batch is a tensor of shape [batch_size, 3, image_size, image_size]\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter out None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "\n",
    "    # Stack the tensors\n",
    "    images, qwen_list = zip(*batch)\n",
    "    images_batch = torch.stack(images)\n",
    "    qwen_batch = torch.stack(qwen_list)\n",
    "\n",
    "    return images_batch, qwen_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfd9fe",
   "metadata": {},
   "source": [
    "## 2. Saving and Plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_plots(train_losses_history, val_losses_history, epoch, checkpoint_dir):\n",
    "    \"\"\"\n",
    "    Function that saves training and validation loss plots for each epoch.\n",
    "\n",
    "    Args:\n",
    "        train_losses_history: List of training losses for each epoch.\n",
    "        val_losses_history: List of validation losses for each epoch.\n",
    "        epoch: Current epoch number (for naming the plot).\n",
    "        checkpoint_dir: Directory where the plot will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses_history, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses_history, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Zoomed-in plot for the last 10 epochs (if available)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    start_idx = max(0, len(train_losses_history) - 10)\n",
    "    epochs_range = range(start_idx, len(train_losses_history))\n",
    "    if len(epochs_range) > 1:\n",
    "        plt.plot(epochs_range, train_losses_history[start_idx:], label='Training Loss', color='blue')\n",
    "        plt.plot(epochs_range, val_losses_history[start_idx:], label='Validation Loss', color='red')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Last 10 Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(checkpoint_dir, f'training_progress_epoch_{epoch+1}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, epoch, train_loss, val_loss, checkpoint_dir, is_best=False, keep_last_n=3):\n",
    "    \"\"\"\n",
    "    Function that saves a checkpoint of the model handling the best N models.\n",
    "\n",
    "    Args:\n",
    "        model: The model to save.\n",
    "        optimizer: The optimizer state to save.\n",
    "        scheduler: The scheduler state to save.\n",
    "        epoch: Current epoch number.\n",
    "        train_loss: Training loss for the current epoch.\n",
    "        val_loss: Validation loss for the current epoch.\n",
    "        checkpoint_dir: Directory where the checkpoint will be saved.\n",
    "        is_best: Boolean indicating if this is the best model so far.\n",
    "        keep_last_n: Number of best models to keep.\n",
    "\n",
    "    Returns:\n",
    "        str: Filename of the saved checkpoint if it is the best model, otherwise None.\n",
    "    \"\"\"\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "    }\n",
    "    \n",
    "    # Save the last checkpoint\n",
    "    torch.save(checkpoint, os.path.join(checkpoint_dir, 'last_checkpoint.pth'))\n",
    "    \n",
    "    if is_best:\n",
    "        # Handle the best N models\n",
    "        best_models_info_path = os.path.join(checkpoint_dir, 'best_models_info.json')\n",
    "        \n",
    "        # Load existing best models info if it exists\n",
    "        if os.path.exists(best_models_info_path):\n",
    "            with open(best_models_info_path, 'r') as f:\n",
    "                best_models = json.load(f)\n",
    "        else:\n",
    "            best_models = []\n",
    "        \n",
    "        # Add the new model info\n",
    "        new_model_info = {\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'filename': f'best_model_epoch_{epoch+1}_loss_{val_loss:.4f}.pth'\n",
    "        }\n",
    "        best_models.append(new_model_info)\n",
    "        \n",
    "        # Order by validation loss and keep only the best N\n",
    "        best_models.sort(key=lambda x: x['val_loss'])\n",
    "        \n",
    "        # Remove worst model files if necessary\n",
    "        if len(best_models) > keep_last_n:\n",
    "            models_to_remove = best_models[keep_last_n:]\n",
    "            for model_info in models_to_remove:\n",
    "                old_file_path = os.path.join(checkpoint_dir, model_info['filename'])\n",
    "                if os.path.exists(old_file_path):\n",
    "                    os.remove(old_file_path)\n",
    "            best_models = best_models[:keep_last_n]\n",
    "        \n",
    "        # Save the new checkpoint\n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, new_model_info['filename']))\n",
    "        \n",
    "        # Update the info file with the new best models\n",
    "        with open(best_models_info_path, 'w') as f:\n",
    "            json.dump(best_models, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n[INFO] New best model saved: {new_model_info['filename']}\")\n",
    "        return new_model_info['filename']\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb25b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer=None, scheduler=None):\n",
    "    \"\"\"\n",
    "    Function that loads a checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file.\n",
    "        model: The model to load the state into.\n",
    "        optimizer: The optimizer to load the state into (optional).\n",
    "        scheduler: The scheduler to load the state into (optional).\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing the epoch number, training loss, and validation loss.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"[INFO] Loading checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Load optimizer and scheduler states if provided\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Retrieve epoch and losses\n",
    "    epoch = checkpoint['epoch']\n",
    "    train_loss = checkpoint.get('train_loss', float('inf'))\n",
    "    val_loss = checkpoint.get('val_loss', float('inf'))\n",
    "    \n",
    "    print(f\"[INFO] Checkpoint loaded: Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    return epoch, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea86db",
   "metadata": {},
   "source": [
    "## 3. Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Class for early stopping during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience=20, min_delta=1e-4, restore_best_weights=True):\n",
    "        \"\"\"\n",
    "        Early stopping to stop training when it no longer improves.\n",
    "\n",
    "        Args:\n",
    "            patience: Number of epochs to wait for improvement before stopping.\n",
    "            min_delta: Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            restore_best_weights: Whether to restore model weights from the epoch with the best validation loss.\n",
    "        \"\"\"\n",
    "\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        Check if training should be stopped.\n",
    "\n",
    "        Args:\n",
    "            val_loss: Current validation loss.\n",
    "            model: The model whose weights may be restored if early stopping is triggered.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if training should be stopped, False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check for improvement\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        # Check if we have reached the patience limit\n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            \n",
    "        return self.early_stop\n",
    "    \n",
    "\n",
    "    def restore_weights(self, model):\n",
    "        \"\"\"\n",
    "        Restore the weights of the model to the best weights found during training.\n",
    "\n",
    "        Args:\n",
    "            model: The model to restore weights to.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.best_weights is not None:\n",
    "            best_weights_on_device = {k: v.to(model.state_dict()[k].device) \n",
    "                                    for k, v in self.best_weights.items()}\n",
    "            model.load_state_dict(best_weights_on_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11135d9b",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5992dd2",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMAGES_FOLDER = os.path.join(\"..\", \"..\", \"CV_data\", \"miniImageNet\")  # Folder containing images\n",
    "QWEN_EMBEDDINGS_PATH = os.path.join(\"..\", \"..\", \"CV_data\", \"separated_embeddings\", \"qwen_384\")  # Folder containing Qwen embeddings\n",
    "CSV_TRAIN = os.path.join(\"..\", \"assets\", \"train_images.csv\")  # CSV file with image filenames of training images\n",
    "\n",
    "# Image parameters\n",
    "IMAGE_SIZE = 384  # Size to which images will be resized (IMAGE_SIZE x IMAGE_SIZE)\n",
    "\n",
    "# Training parameters\n",
    "TRAIN_SIZE = 0.8  # Proportion of data used for training\n",
    "BATCH_SIZE = 8  # Batch size for training and validation\n",
    "LEARNING_RATE_RESNET = 1e-4  # Learning rate for the ResNet backbone\n",
    "LEARNING_RATE_ADAPTER = 1e-4  # Learning rate for the adapter layers\n",
    "WEIGHT_DECAY = 1e-3  # Weight decay for optimizer\n",
    "MAX_EPOCHS = 100  # Maximum number of epochs\n",
    "CHECKPOINT_DIR = os.path.join(\"..\", \"models\", \"MultiStage_FtResnet_V2\")  # Directory to save checkpoints\n",
    "RESUME_TRAINING = True  # Whether to resume training from the last checkpoint\n",
    "KEEP_BEST_N = 3  # Number of best models to keep\n",
    "PLOT_SAVE_INTERVAL = 5  # Save plots every n epochs\n",
    "\n",
    "# Early stopping parameters\n",
    "EARLY_STOPPING_PATIENCE = 5  # Number of epochs with no improvement to wait before stopping\n",
    "EARLY_STOPPING_MIN_DELTA = 1e-3  # Minimum change in validation loss to qualify as improvement\n",
    "\n",
    "# Create the checkpoint directory if it doesn't exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60fe4ca",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image filenames from the CSV\n",
    "images_csv = pd.read_csv(CSV_TRAIN)\n",
    "images_list = images_csv['filename'].tolist()\n",
    "\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "dataset = ImageQwenDataset(IMAGES_FOLDER, QWEN_EMBEDDINGS_PATH, images_list, image_size=IMAGE_SIZE)\n",
    "\n",
    "train_size = int(TRAIN_SIZE * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d1e73",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9108be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model setting parameters for training and fine-tuning\n",
    "model = CompositeModel().to(device)\n",
    "\n",
    "for param in model.resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.adapter.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "\n",
    "# Define optimizer, scheduler, loss function, and scaler\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.resnet.parameters(), 'lr': LEARNING_RATE_RESNET},\n",
    "    {'params': model.adapter.parameters(), 'lr': LEARNING_RATE_ADAPTER}\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-5, threshold=0\n",
    ")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "scaler = torch.amp.GradScaler(device)\n",
    "\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=EARLY_STOPPING_PATIENCE, \n",
    "    min_delta=EARLY_STOPPING_MIN_DELTA, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Tracking variables\n",
    "best_val_loss = float('inf')\n",
    "start_epoch = 0\n",
    "train_losses_history = []\n",
    "val_losses_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca9e01",
   "metadata": {},
   "source": [
    "### Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd468f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training if specified\n",
    "if RESUME_TRAINING:\n",
    "    last_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'last_checkpoint.pth')\n",
    "    if os.path.exists(last_checkpoint_path):\n",
    "        try:\n",
    "            # Load the last checkpoint if it exists\n",
    "            start_epoch, last_train_loss, best_val_loss = load_checkpoint(\n",
    "                last_checkpoint_path, model, optimizer, scheduler\n",
    "            )\n",
    "            start_epoch += 1\n",
    "            \n",
    "            # Load history if available\n",
    "            history_path = os.path.join(CHECKPOINT_DIR, 'loss_history.json')\n",
    "            if os.path.exists(history_path):\n",
    "                with open(history_path, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                    train_losses_history = history.get('train_losses', [])\n",
    "                    val_losses_history = history.get('val_losses', [])\n",
    "            \n",
    "            # Update early stopping with previous history\n",
    "            if val_losses_history:\n",
    "                early_stopping.best_loss = min(val_losses_history)\n",
    "                best_epoch_idx = val_losses_history.index(early_stopping.best_loss)\n",
    "                early_stopping.counter = len(val_losses_history) - 1 - best_epoch_idx\n",
    "                print(f\"[INFO] Early stopping restored: best_loss={early_stopping.best_loss:.4f}, counter={early_stopping.counter}\")\n",
    "\n",
    "            print(f\"[INFO] Training resumed from epoch {start_epoch}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error loading checkpoint: {e}\")\n",
    "            print(\"[INFO] Start new training from scratch...\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(\"[INFO] No checkpoint found. Starting new training from scratch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8108620",
   "metadata": {},
   "source": [
    "### Epoch training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_training(model, train_dataloader, loss_function, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    Function to train the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_dataloader: DataLoader for the training data.\n",
    "        loss_function: Loss function to use.\n",
    "        optimizer: Optimizer to use.\n",
    "        scaler: GradScaler for mixed precision training.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean training loss for the epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_loop = tqdm(train_dataloader, desc=f\"[LOOP] Training\")\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for i, batch_data in enumerate(train_loop):\n",
    "        # Skip batches with None values\n",
    "        if batch_data[0] is None:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Get data and move to device\n",
    "            imgs, qwen_embs = batch_data\n",
    "            imgs = imgs.to(device)\n",
    "            qwen_embs = qwen_embs.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with mixed precision\n",
    "            with torch.amp.autocast(device):\n",
    "                target_seq_len = qwen_embs.shape[1]\n",
    "                pred = model(imgs, target_seq_len=target_seq_len)\n",
    "                loss = loss_function(pred, qwen_embs)\n",
    "\n",
    "            # Check for NaN or Inf loss\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"[ERROR] Invalid loss at batch {i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Record loss\n",
    "            train_losses.append(loss.item())\n",
    "            train_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error at batch {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Compute mean training loss\n",
    "    mean_loss = np.mean(train_losses) if train_losses else float('inf')\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_validation(model, val_dataloader, loss_function):\n",
    "    \"\"\"\n",
    "    Function to validate the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: The model to validate.\n",
    "        val_dataloader: DataLoader for the validation data.\n",
    "        loss_function: Loss function to use.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean validation loss for the epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_loop = tqdm(val_dataloader, desc=f\"[LOOP] Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over batches\n",
    "        for i, batch_data in enumerate(val_loop):\n",
    "            # Skip batches with None values\n",
    "            if batch_data[0] is None:\n",
    "                continue\n",
    "            \n",
    "            # Get data and move to device\n",
    "            imgs, qwen_embs = batch_data\n",
    "            imgs = imgs.to(device)\n",
    "            qwen_embs = qwen_embs.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision\n",
    "            with torch.amp.autocast(device):\n",
    "                pred = model(imgs, target_seq_len=qwen_embs.shape[1])\n",
    "                loss = loss_function(pred, qwen_embs)\n",
    "\n",
    "            # Check for NaN or Inf loss\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"[ERROR] Invalid loss at batch {i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Record loss\n",
    "            val_losses.append(loss.item())\n",
    "            val_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    # Compute mean validation loss\n",
    "    mean_loss = np.mean(val_losses) if val_losses else float('inf')\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47875a8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1060563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_evaluation(model, train_loss, val_loss, optimizer, scheduler, epoch, early_stopping):\n",
    "    \"\"\"\n",
    "    Function that evaluates the model at the end of each epoch, updates the learning rate,\n",
    "    checks for early stopping, and saves the model checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model: The model to evaluate.\n",
    "        train_loss: Training loss for the current epoch.\n",
    "        val_loss: Validation loss for the current epoch.\n",
    "        optimizer: Optimizer used for training.\n",
    "        scheduler: Learning rate scheduler.\n",
    "        epoch: Current epoch number.\n",
    "        early_stopping: EarlyStopping instance to check for stopping conditions.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if training should stop, False otherwise.\n",
    "        train_loss: Training loss for the current epoch.\n",
    "        val_loss: Validation loss for the current epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Save training and validation losses\n",
    "    train_losses_history.append(train_loss)\n",
    "    val_losses_history.append(val_loss)\n",
    "    \n",
    "    # Update scheduler\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Epoch results\n",
    "    print(f\"\\n[INFO] EPOCH RESULTS {epoch + 1}:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"   Learning Rate: {new_lr:.2e}\")\n",
    "\n",
    "    print(f\"\\n[INFO] Scheduler state: {scheduler.num_bad_epochs}/{scheduler.patience}\")\n",
    "\n",
    "    if old_lr != new_lr:\n",
    "        print(f\"[INFO] LR reduced: {old_lr:.2e} → {new_lr:.2e}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(f\"\\n[INFO] EARLY STOPPING ACTIVATED!\")\n",
    "        print(f\"   Epoch: {epoch + 1}\")\n",
    "        print(f\"   Best val_loss: {early_stopping.best_loss:.4f}\")\n",
    "        print(f\"   Epochs without improvement: {early_stopping.patience}\")\n",
    "        \n",
    "        if early_stopping.restore_best_weights:\n",
    "            early_stopping.restore_weights(model)\n",
    "            print(\"[INFO] Restored weights of the best model\")\n",
    "                    \n",
    "        # Save the best model checkpoint\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, train_loss, \n",
    "                        early_stopping.best_loss, CHECKPOINT_DIR, is_best=True, keep_last_n=KEEP_BEST_N)\n",
    "        \n",
    "        return True, train_loss, val_loss\n",
    "\n",
    "    print(f\"[INFO] Early stopping: {early_stopping.counter}/{early_stopping.patience}\")\n",
    "    return False, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e7585",
   "metadata": {},
   "source": [
    "### Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ec43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_completed = False\n",
    "completion_reason = \"unknown\"\n",
    "\n",
    "try:\n",
    "    # Main training loop over epochs\n",
    "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
    "        print(f\"\\n[TRAINING] EPOCH {epoch + 1}/{MAX_EPOCHS}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Training\n",
    "        train_loss = epoch_training(model, train_loader, loss_function, optimizer, scaler)\n",
    "        if train_loss is None:\n",
    "            continue\n",
    "\n",
    "        # Validation\n",
    "        val_loss = epoch_validation(model, val_loader, loss_function)\n",
    "        if val_loss is None:\n",
    "            continue\n",
    "\n",
    "        # Evaluation\n",
    "        stopped, avg_train_loss, avg_val_loss = epoch_evaluation(model, train_loss, val_loss, optimizer, scheduler, epoch, early_stopping)\n",
    "        if stopped:\n",
    "            training_completed = True\n",
    "            completion_reason = \"early_stopping\"\n",
    "            break\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss, CHECKPOINT_DIR)\n",
    "        \n",
    "        # Save best model\n",
    "        is_best = avg_val_loss < best_val_loss\n",
    "        if is_best:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss, \n",
    "                CHECKPOINT_DIR, is_best=True, keep_last_n=KEEP_BEST_N\n",
    "            )\n",
    "\n",
    "        # Save plots every n epochs\n",
    "        if (epoch + 1) % PLOT_SAVE_INTERVAL == 0:\n",
    "            save_training_plots(train_losses_history, val_losses_history, epoch, CHECKPOINT_DIR)\n",
    "        \n",
    "        # Save loss history\n",
    "        history = {\n",
    "            'train_losses': train_losses_history,\n",
    "            'val_losses': val_losses_history\n",
    "        }\n",
    "        with open(os.path.join(CHECKPOINT_DIR, 'loss_history.json'), 'w') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "    \n",
    "    # If max epochs reached without early stopping\n",
    "    if not training_completed:\n",
    "        completion_reason = \"max_epochs_reached\"\n",
    "        training_completed = True\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n[INFO] Training manually interrupted at epoch {epoch + 1}\")\n",
    "    completion_reason = \"manual_interruption\"\n",
    "    training_completed = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] Error during training: {e}\")\n",
    "    print(\"\\nStack trace:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"Saving current state...\")\n",
    "    save_checkpoint(model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss, CHECKPOINT_DIR)\n",
    "    completion_reason = \"error\"\n",
    "    training_completed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ce862",
   "metadata": {},
   "source": [
    "## 5. Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6180fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch = epoch + 1 if 'epoch' in locals() else start_epoch\n",
    "\n",
    "# Final report\n",
    "print(\"[TRAINING] Completed\")\n",
    "print(\"=\"*50)\n",
    "print(f\"[INFO] Effective epochs: {final_epoch}\")\n",
    "print(f\"[INFO] Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Completion reason\n",
    "if completion_reason == \"early_stopping\":\n",
    "    print(f\"[INFO] Stopped with early stopping after {early_stopping.patience} epochs without improvement\")\n",
    "elif completion_reason == \"max_epochs_reached\":\n",
    "    print(\"[INFO] All scheduled epochs completed\")\n",
    "elif completion_reason == \"manual_interruption\":\n",
    "    print(\"[INFO] Training manually interrupted\")\n",
    "elif completion_reason == \"error\":\n",
    "    print(\"[ERROR] Training stopped due to an error\")\n",
    "\n",
    "\n",
    "# Save final plots\n",
    "if train_losses_history:\n",
    "    save_training_plots(train_losses_history, val_losses_history, final_epoch-1, CHECKPOINT_DIR)\n",
    "\n",
    "# Best models info\n",
    "best_models_info_path = os.path.join(CHECKPOINT_DIR, 'best_models_info.json')\n",
    "if os.path.exists(best_models_info_path):\n",
    "    with open(best_models_info_path, 'r') as f:\n",
    "        best_models = json.load(f)\n",
    "    print(f\"\\n[INFO] Best {len(best_models)} models saved:\")\n",
    "    for i, model_info in enumerate(best_models):\n",
    "        print(f\"   {i+1}. Epoch {model_info['epoch']+1}: {model_info['filename']}\")\n",
    "        print(f\"      Val Loss: {model_info['val_loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
